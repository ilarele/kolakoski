{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch import Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(dataset):\n",
    "    mean, std = dataset.mean(), dataset.std()\n",
    "    result = (dataset - mean)/std\n",
    "\n",
    "    print(\"min, max\", result.min(), result.max())\n",
    "    print(\"mean, std\", mean, std)\n",
    "    return result\n",
    "\n",
    "dir_path = \"dataset/1e8_unique\"\n",
    "dataset_np = np.load(\"%s/kolakosky.npy\" % dir_path).astype(np.float32)\n",
    "idxs_train = np.load(\"%s/train_idxs.npy\" % dir_path)\n",
    "idxs_valid = np.load(\"%s/valid_idxs.npy\" % dir_path)\n",
    "\n",
    "# normalize numbers\n",
    "dataset_np[:, 1:-1] = normalize(dataset_np[:, 1:-1])\n",
    "\n",
    "print(dataset_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_np[0, 1:-1], dataset_np[:, 1:-1].min(), dataset_np[:, 1:-1].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets\n",
    "trainset, validset = torch.Tensor(dataset_np[idxs_train]), torch.Tensor(dataset_np[idxs_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader\n",
    "batch_size = 1500\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=5)\n",
    "validloader = torch.utils.data.DataLoader(validset, batch_size=len(validset), shuffle=False, num_workers=1)\n",
    "\n",
    "print(\"trainset\", len(trainset), len(trainloader))\n",
    "print(\"validset\", len(validset), len(validloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_epoch(net, dloader, epoch):\n",
    "    with torch.no_grad():\n",
    "        valid_loss = 0\n",
    "        valid_acc = 0\n",
    "        num_correct = 0\n",
    "        \n",
    "        for i, data in enumerate(dloader):\n",
    "            inputs, labels = data[:, 1:-1].cuda(), data[:, -1].long().cuda()\n",
    "            outputs = net(inputs)\n",
    "\n",
    "            # loss\n",
    "            valid_loss += criterion(outputs, labels).item() * data.shape[0]\n",
    "\n",
    "            # acc\n",
    "            (_, arg_maxs) = Tensor.max(outputs.data, dim=1)\n",
    "            num_correct += Tensor.sum(labels==arg_maxs)\n",
    "    \n",
    "    acc = (num_correct * 100.0 / len(validset)).item()\n",
    "    loss = valid_loss/len(validset)\n",
    "    print(\"[Epoch %d] Eval Acc %.2f%% (Loss %.3f)\" % (epoch, acc, loss))\n",
    "    return acc, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net1(nn.Module):\n",
    "    def __init__(self, n_inputs):\n",
    "        super(Net1, self).__init__()\n",
    "        self.fc1 = nn.Linear(n_inputs, 34)\n",
    "        self.fc2 = nn.Linear(34, 50)\n",
    "        self.fc3 = nn.Linear(50, 256)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "class Net2(nn.Module):\n",
    "    def __init__(self, n_inputs):\n",
    "        super(Net2, self).__init__()\n",
    "        self.fc1 = nn.Linear(n_inputs, 60)\n",
    "        self.fc2 = nn.Linear(60, 150)\n",
    "        self.fc3 = nn.Linear(150, 250)\n",
    "        self.fc4 = nn.Linear(250, 300)\n",
    "        self.fc5 = nn.Linear(300, 500)\n",
    "        self.fc6 = nn.Linear(500, 256)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = F.relu(self.fc5(x))\n",
    "        x = self.fc6(x)\n",
    "        return x\n",
    "    \n",
    "class Net3(nn.Module):\n",
    "    def __init__(self, n_inputs):\n",
    "        super(Net3, self).__init__()\n",
    "        self.fc1 = nn.Linear(n_inputs, 60)\n",
    "        self.fc2 = nn.Linear(60, 150)\n",
    "        self.fc3 = nn.Linear(150, 250)\n",
    "        self.fc4 = nn.Linear(250, 300)\n",
    "        self.fc5 = nn.Linear(300, 500)\n",
    "        self.fc6 = nn.Linear(500, 700)\n",
    "        self.fc7 = nn.Linear(700, 500)\n",
    "        self.fc8 = nn.Linear(500, 300)\n",
    "        self.fc9 = nn.Linear(300, 256)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = F.relu(self.fc5(x))\n",
    "        x = F.relu(self.fc6(x))\n",
    "        x = F.relu(self.fc7(x))\n",
    "        x = F.relu(self.fc8(x))\n",
    "        x = self.fc9(x)\n",
    "        return x\n",
    "\n",
    "net = Net3(n_inputs=40).cuda()\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = optim.AdamW(net.parameters(), lr=1e-3)\n",
    "last_saved_eval_acc = 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_params = sum(p.numel() for p in net.parameters())\n",
    "print(\"Total params\", total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = optim.AdamW(net.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print_iter = int(150000/batch_size)\n",
    "\n",
    "class_str = str(net.__class__).replace(\"'>\", \"\").split(\".\")[1]\n",
    "# CHECKPOINT_PATH = \"nn_checkpoints/40feat_unique_81e8_FConly_%.0f_%s.pth\" % (last_saved_eval_acc, class_str)\n",
    "# net.load_state_dict(torch.load(CHECKPOINT_PATH))\n",
    "\n",
    "for epoch in range(1, 500):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data[:, 1:-1].cuda(), data[:, -1].long().cuda()\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % print_iter == print_iter-1:    # print every 20 mini-batches\n",
    "            print('[%d, %5d] loss: %.4f' %\n",
    "                  (epoch + 1, i + 1, running_loss / print_iter))\n",
    "            running_loss = 0.0\n",
    "    eval_acc, _ = eval_epoch(net, validloader, epoch)\n",
    "    if int(eval_acc) > last_saved_eval_acc:\n",
    "        last_saved_eval_acc = int(eval_acc)\n",
    "        CHECKPOINT_PATH = \"nn_checkpoints/40feat_unique_81e8_FConly_%.0f_%s.pth\" % (last_saved_eval_acc, class_str)\n",
    "        torch.save(net.state_dict(), CHECKPOINT_PATH)\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
